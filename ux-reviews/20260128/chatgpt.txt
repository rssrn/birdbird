Below is a structured UX review of the three primary views (Highlights, Video Stats, Audio Stats), written from the perspective of a UX consultant evaluating an earlyâ€“mid stage data-rich product. Iâ€™ll focus on information design, layout, interaction patterns, clarity, and trust, and Iâ€™ll distinguish quick wins from deeper design opportunities.

1. Overall Product & UX Framing
What works well

Clear purpose: â€œBird Feeder Highlightsâ€ and the subtitle (â€œAutomated bird activity highlightsâ€¦â€) immediately communicate intent.

Consistent visual language: Calm, natural palette fits the subject matter; nothing visually jarring.

Structured navigation: Date ranges + tabs (Highlights / Video Stats / Audio Stats) are familiar and predictable.

Credibility signals: Confidence percentages, model names, and dataset attribution reinforce trust.

High-level UX risks

Cognitive load: The interface is information-dense without enough summarisation or hierarchy.

Expert bias: Model-related terms (YOLOv8, BioCLIP, confidence ranges) are accurate but may overwhelm non-technical users.

Ambiguity between â€œdetectionsâ€, â€œcountsâ€, and â€œconfidenceâ€: Users may not fully understand what numbers represent in real-world terms.

2. Global Navigation & Layout
Date Range Selector (Top)

Strengths

Clearly scoped time windows

Active date visually highlighted

Issues

Looks like tabs, behaves like filters â†’ conceptual mismatch

No indication of:

Total activity per date

Whether data volume differs significantly between ranges

Improvements

Add light metadata under each date (e.g. â€œ142 clipsâ€, â€œ23 detectionsâ€)

Consider a dropdown + calendar picker for advanced users

Visually separate date navigation from content tabs (they currently compete)

Tabs: Highlights / Video Stats / Audio Stats

Strengths

Logical segmentation

Persistent across views (good spatial memory)

Improvements

Add 1-line explainer subtitle per tab, e.g.:

Highlights: â€œBest examples per speciesâ€

Video Stats: â€œOn-camera visual detectionsâ€

Audio Stats: â€œOff-camera sound detectionsâ€

Consider badges (e.g. â€œ13 speciesâ€, â€œ4 vocal speciesâ€) to aid scanning

3. Audio Stats View (Screenshot 1)
What works

Clear distinction that these are off-camera vocalisations

Ranking by frequency is intuitive

Confidence ranges communicate uncertainty well

Issues & Opportunities
3.1 Information Density

Long vertical list with similar visual weight

Rare detections (1 count) look equally important as dominant ones

Improvements

Introduce grouping or thresholds, e.g.:

â€œCommon vocalisationsâ€

â€œOccasionalâ€

â€œSingle detectionsâ€

Collapse species with count = 1 into an expandable section

3.2 Confidence Representation

Confidence ranges (e.g. 55â€“94%) are accurate but abstract

Improvements

Add qualitative labels:

High confidence

Mixed confidence

Low confidence

Or show a median confidence dot inside the bar

3.3 Audio Controls

Icons (play, waveform, speaker, menu) are compact but ambiguous

Issues

Unclear difference between:

Play vs waveform

Speaker vs play

Improvements

Add tooltips on hover

Consider merging play + waveform into a single audio preview control

Highlight which clip is â€œbest exampleâ€

4. Video Stats View (Screenshot 2)
What works

Strong scannability: counts + bars make dominance obvious

Blue Tit / Great Tit dominance immediately clear

Confidence ranges feel more credible for visual ID

Issues & Improvements
4.1 Counts Without Context

â€œ115 Blue Tit detectionsâ€ sounds impressive, but:

Over how many clips?

Over how many hours?

Same individual or multiple?

Improvements

Add contextual framing at top:

â€œ234 motion clips analysed Â· 312 total detectionsâ€

Consider optional normalisation:

Detections per day

% of total detections

4.2 Species List Length

Long tail of single detections visually competes with common species

Improvements

Visually de-emphasise rare species (lighter text, grouped section)

Allow sorting:

By count

By confidence

Alphabetically

4.3 Confidence Ranges

Ranges like â€œ53â€“100%â€ are technically sound but cognitively noisy

Improvements

Replace ranges with:

Median confidence + min/max on hover

Or a small sparkline-style confidence indicator

5. Highlights View (Screenshot 3)

This is the most emotionally engaging view â€” and the one with the biggest UX opportunity.

What works

Video preview is central and visually dominant (correct priority)

Species list on the left provides fast navigation

Probability labels (Very Probable / Probable / Possible) are excellent

Key Issues & Improvements
5.1 Species Navigation (Left Panel)

Issues

Repeated species list across tabs feels redundant

Users donâ€™t know why one clip is chosen as â€œbestâ€

Improvements

Add microcopy:

â€œBest-confidence clip per speciesâ€

Show:

Confidence %

Duration

Time of day

Allow filtering:

â€œShow only Very Probableâ€

5.2 Video Player Context

Issues

The video appears without enough explanatory framing

â€œBatch Informationâ€ is hidden, but likely important

Improvements

Add a context header above video:

Blue Tit Â· 94% confidence Â· 26 Jan, 09:14

Surface key metadata inline, not hidden:

Detection confidence

Clip length

Detection method (vision)

5.3 Trust & Interpretation

Users may wonder:

â€œHow confident should I really be this is a Blue Tit?â€

Improvements

Add a subtle confidence explainer tooltip:

â€œConfidence reflects model agreement, not certaintyâ€

Optionally show top 2 alternative species if close

6. Accessibility & Usability
Accessibility Positives

High contrast text

Clear typography

Logical reading order

Improvements

Ensure all icon-only controls have:

ARIA labels

Keyboard focus states

Increase clickable area on small icons

Consider a reduced-motion or â€œdata-onlyâ€ mode

7. Strategic UX Enhancements (Beyond UI Polish)
7.1 Summary Layer (Very High Impact)

Add a daily/period summary card at the top of each date:

â€œ14 species detectedâ€

â€œMost common: Blue Titâ€

â€œNew this period: Marsh Titâ€

â€œAudio-only detections: 8â€

This dramatically improves first-time comprehension.

7.2 Progressive Disclosure

Right now, everything is visible immediately.

Introduce:

Beginner mode: summaries + highlights

Advanced mode: full stats, confidence ranges, model details

7.3 Narrative Framing

Youâ€™re sitting on a storytelling product.

Examples:

â€œThis week, Blue Tits dominated the feeder, with a rare Marsh Tit appearance.â€

â€œAudio picked up a Green Sandpiper overnight â€” no visual confirmation.â€

This turns data into insight.

Final Assessment

Overall UX maturity: 7.5 / 10

Technically credible

Visually calm and consistent

Strong foundations for trust and exploration

Main UX opportunity:
ğŸ‘‰ Reduce cognitive load and add interpretive scaffolding â€” help users understand what matters without reading everything.

If youâ€™d like, next steps could include:

A reworked wireframe for one view

A persona-based critique (casual birder vs data enthusiast)

Copywriting improvements for clarity and tone

A prioritised UX backlog (quick wins vs structural changes)

Just say how deep you want to go.
